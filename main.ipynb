{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "########################\n",
        "# Importing libraries\n",
        "########################\n",
        "# System libraries\n",
        "import os\n",
        "import random\n",
        "from time import gmtime, strftime\n",
        "import numpy as np\n",
        "import pickle\n",
        "import copy\n",
        "import pdb\n",
        "\n",
        "# Tensorboard for PyTorch logging and visualization\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Torch libraries\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "# Custom library\n",
        "import lib.Models.architectures as architectures\n",
        "import lib.Datasets.datasets as datasets\n",
        "from lib.Models.initialization import WeightInit\n",
        "from lib.cmdparser import parser\n",
        "from lib.Training.train import train\n",
        "from lib.Training.validate import validate\n",
        "from lib.Training.test import test\n",
        "from lib.Training.loss_functions import loss_function as criterion\n",
        "from lib.Utility.utils import save_checkpoint, save_task_checkpoint\n",
        "from lib.Utility.visualization import args_to_tensorboard\n",
        "\n",
        "\n",
        "# Comment this if CUDNN benchmarking is not desired\n",
        "cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Command line options\n",
        "    args = parser.parse_args()\n",
        "    print(\"Command line options:\")\n",
        "    for arg in vars(args):\n",
        "        print(arg, getattr(args, arg))\n",
        "\n",
        "    if args.debug:\n",
        "        pdb.set_trace()\n",
        "\n",
        "    # Check whether GPU is available and can be used\n",
        "    # if CUDA is found then device is set accordingly\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Launch a writer for the tensorboard summary writer instance\n",
        "    save_path = 'runs/' + strftime(\"%Y-%m-%d_%H-%M-%S\", gmtime()) + '_' + args.dataset + '_' + args.architecture\n",
        "\n",
        "    # if we are resuming a previous training, note it in the name\n",
        "    if args.resume:\n",
        "        save_path = save_path + '_resumed'\n",
        "    writer = SummaryWriter(save_path)\n",
        "\n",
        "    # saving the parsed args to file\n",
        "    log_file = os.path.join(save_path, \"stdout\")\n",
        "    log = open(log_file, \"a\")\n",
        "    for arg in vars(args):\n",
        "        log.write(arg + ':' + str(getattr(args, arg)) + '\\n')\n",
        "\n",
        "    # Dataset loading\n",
        "    data_init_method = getattr(datasets, args.dataset)\n",
        "    dataset = data_init_method(torch.cuda.is_available(), args)\n",
        "    # get the number of classes from the class dictionary\n",
        "    num_classes = dataset.num_classes\n",
        "\n",
        "    # we set an epoch multiplier to 1 for isolated training and increase it proportional to amount of tasks in CL\n",
        "    epoch_multiplier = 1\n",
        "\n",
        "    # add command line options to TensorBoard\n",
        "    args_to_tensorboard(writer, args)\n",
        "    log.close()\n",
        "    \n",
        "    # build the model\n",
        "    model = architectures.Inos_model(args.num_class, args)\n",
        "\n",
        "    # Parallel container for multi GPU use and cast to available device\n",
        "    model = torch.nn.DataParallel(model).to(device)\n",
        "    print(model)\n",
        "\n",
        "    if not args.pretrained :\n",
        "        # Initialize the weights of the model, by default according to He et al.\n",
        "        print(\"Initializing network with: \" + args.weight_init)\n",
        "        WeightInitializer = WeightInit(args.weight_init)\n",
        "        WeightInitializer.init_model(model)\n",
        "\n",
        "    # Define optimizer and loss function (criterion)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), args.learning_rate, momentum=0.9, weight_decay=2e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,60,80,100], gamma=0.5)\n",
        "\n",
        "    epoch = 0\n",
        "    best_prec = 0\n",
        "    best_loss = random.getrandbits(128)\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            epoch = checkpoint['epoch']\n",
        "            best_prec = checkpoint['best_prec']\n",
        "            best_loss = checkpoint['best_loss']\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            # optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(args.resume, checkpoint['epoch']))\n",
        "        else:\n",
        "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "    # optimize until final amount of epochs is reached. Final amount of epochs is determined through the\n",
        "    while epoch < (args.epochs * epoch_multiplier):\n",
        "        if epoch+2 == epoch%args.epochs:\n",
        "            print(\"debug perpose\")\n",
        "\n",
        "        # train\n",
        "        train(dataset, model, criterion, epoch, optimizer, writer, device, args)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        prec, loss = validate(dataset, model, criterion, epoch, writer, device, save_path, args)\n",
        "\n",
        "        # evaluate on test set\n",
        "        prec_t, loss_t = test(dataset, model, criterion, epoch, writer, device, save_path, args)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = loss < best_loss\n",
        "        best_loss = min(loss, best_loss)\n",
        "        best_prec = max(prec, best_prec)\n",
        "        save_checkpoint({'epoch': epoch,\n",
        "                         'arch': args.architecture,\n",
        "                         'state_dict': model.state_dict(),\n",
        "                         'best_prec': best_prec,\n",
        "                         'best_loss': best_loss,\n",
        "                         'optimizer': optimizer.state_dict()},\n",
        "                        is_best, save_path)\n",
        "\n",
        "        # increment epoch counters\n",
        "        epoch += 1\n",
        "        scheduler.step()\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':     \n",
        "    main()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}